{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2VvI0_5bTip"
      },
      "source": [
        "## Wstęp do Uczenia Maszynowego\n",
        "\n",
        "#### Laboratorium 01\n",
        "\n",
        "### 0\\. Sprawy organizacyjne\n",
        "\n",
        "Kontakt: MS Teams, anna.kozak@pw.edu.pl, katarzyna.woznica@pw.edu.pl\n",
        "\n",
        "Pracujemy z językiem `Python`.\n",
        "\n",
        "Pracujemy z repozytorium GitHub: [https://github.com/kozaka93/2025Z-MachineLearning](https://github.com/kozaka93/2025Z-MachineLearning)\n",
        "\n",
        "Na repozytorium będą się pojawiały pliki `.ipynb` z materiałami na zajęcia.\n",
        "\n",
        "Rozwiązania prac domowych i projektu będę przesyłane na wskazany adres mail w wyznaczonym terminie.\n",
        "\n",
        "*Zasady zaliczenia:*\n",
        "\n",
        "  - 3 x praca domowa (3 x 15p) - raport + kod\n",
        "  - projekt (35p) - raport + kod + odpowiedź ustna\n",
        "\n",
        "Aby zaliczyć laboratoria, należy uzyskać ponad 40 punktów ogółem, w tym co najmniej 15 punktów z projektu. Na podstawie punktów jest wystawiana ocena z części laboratoryjnej.\n",
        "\n",
        "| Ocena | 3 | 3.5 | 4 | 4.5 | 5 |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "| Punkty | (40, 48] | (48, 56] | (56, 64] | (64, 72] | (72, ∞) |\n",
        "\n",
        "Z oceną za laboratoria przystępuje się do egzaminu ustnego.\n",
        "\n",
        "-----\n",
        "\n",
        "### 1\\. Czym będziemy się zajmować?\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"tematy.png\" alt=\"drawing\" width=\"800\">\n",
        "\n",
        "W uczeniu maszynowym pracujemy ze zbiorem danych $\\mathbf{D}= (X, Y)$.\n",
        "\n",
        "  - $X$ to **macierz cech** (zmiennych niezależnych) o wymiarze $n \\times p$ ($n$ próbek, $p$ cech).\n",
        "  - $Y$ to **wektor zmiennej docelowej** (etykieta, wynik, który chcemy przewidzieć) o wymiarze $n$.\n",
        "\n",
        "#### Rodzaje Uczenia Maszynowego\n",
        "\n",
        "1.  **Uczenie nadzorowane (Supervised Learning):** Jeżeli wartość $Y$ jest znana w zbiorze treningowym (czyli mamy dane wejściowe **i** poprawne odpowiedzi). Chcemy, aby model nauczył się mapowania $X \\rightarrow Y$.\n",
        "      * **Regresja (Regression):** Gdy zmienna $Y$ jest ciągła (np. zarobki, temperatura, cena domu, czyli $Y \\in R$).\n",
        "      * **Klasyfikacja (Classification):** Gdy zmienna $Y$ jest dyskretna (kategorie, klasy, np. tak/nie, kot/pies/mysz, czyli $Y \\in \\{0, 1, 2, ..\\}$). Gdy $Y \\in \\{0,1\\}$ mówimy o klasyfikacji binarnej.\n",
        "2.  **Uczenie nienadzorowane (Unsupervised Learning):** Jeżeli nie znamy wartości $Y$ (brakuje nam etykiet). Celem jest znalezienie ukrytych wzorców i struktury w samych danych $X$ (np. grupowanie danych w skupienia).\n",
        "\n",
        "-----\n",
        "\n",
        "### 2\\. Jak wygląda proces uczenia?\n",
        "\n",
        "Proces uczenia maszynowego polega na stworzeniu **modelu** $\\mathbf{M}$, który na podstawie danych wejściowych $X$ potrafi przewidzieć wartość docelową $\\hat{Y}$.\n",
        "\n",
        "**Model:** $\\mathbf{M}: D \\rightarrow \\hat{Y}$\n",
        "\n",
        "**Prognoza:** $\\hat{Y} = M(X)$ .\n",
        "\n",
        "Model jest \"uczony\" na danych $D$, aby jak najlepiej minimalizować błąd między przewidywanym $\\hat{Y}$ a rzeczywistym $Y$.\n",
        "\n",
        "-----\n",
        "\n",
        "### 3\\. Etapy uczenia maszynowego\n",
        "\n",
        "#### 3.1 Pakiety i dane\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wf3WKIrbTiv"
      },
      "outputs": [],
      "source": [
        "# Import potrzebnych pakietów (bibliotek)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 'sklearn' (scikit-learn)  biblioteka do uczenia maszynowego w Pythonie.\n",
        "# Z niej importujemy konkretne algorytmy, np. 'tree' (Drzewa Decyzyjne).\n",
        "from sklearn import tree\n",
        "\n",
        "# Będziemy też potrzebować funkcji do podziału danych\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Metryka do oceny modelu (np. błęd średniokwadratowy)\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxrXgVgKbTix"
      },
      "source": [
        "Rozważmy zbiór danych zawierający informacje o zarobkach zawodników Baseballu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCtlrTShbTix"
      },
      "outputs": [],
      "source": [
        "# Zbiory danych można wczytać przez link z GitHub, nie ma koniecznośći ich pobierania.\n",
        "# index_col =[0] mówi, aby pierwszą kolumnę pliku CSV potraktować jako indeks wierszy.\n",
        "Hitters = pd.read_csv(\"https://raw.githubusercontent.com/kozaka93/2025Z-MachineLearning/refs/heads/main/labs/lab01/Hitters.csv\", index_col =[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76i5QXF0bTiy"
      },
      "outputs": [],
      "source": [
        "Hitters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHxy27oIbTiz"
      },
      "source": [
        "-----\n",
        "\n",
        "#### 3.2 Przygotowanie danych (Pre-processing)\n",
        "\n",
        "##### *Zadanie 1*\n",
        "\n",
        "-----\n",
        "\n",
        "Przygotuj zbiór danych do zbudowania pierwszego modelu.\n",
        "\n",
        "a) Utwórz zbiór *Hitters\\_small* zawierający zmienne o nazwach *Years, Hits, Salary*.\n",
        "\n",
        "b) Przyjrzyj się utworzonemu zbiorowi danych. Jaki jest wymiar danych, typy zmiennych, czy są braki danych? Jakie rozkłady mają zmienne?\n",
        "\n",
        "c) Podziel zbiór danych na X = ['Years', 'Hits'] (cechy) i y = ['Salary'] (zmienna docelowa).\n",
        "\n",
        "d) Podziel dane na zbiór treningowy i testowy (proporcja 50:50).\n",
        "\n",
        "**Rozwiązanie Zadania 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAQwIP5vbTiz"
      },
      "outputs": [],
      "source": [
        "# a) \n",
        "\n",
        "# Tworzymy nowy DataFrame, wybierając tylko potrzebne kolumny.\n",
        "Hitters_small = Hitters[[\"Years\", \"Hits\", \"Salary\"]]\n",
        "\n",
        "Hitters_small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmO9p8-FbTi0"
      },
      "outputs": [],
      "source": [
        "# b) Analiza danych (Exploratory Data Analysis - EDA)\n",
        "\n",
        "# 1. Wymiar danych: .shape zwraca krotkę (liczba wierszy, liczba kolumn)\n",
        "print(\"Wymiar danych (wiersze x kolumny):\", Hitters_small.shape)\n",
        "\n",
        "# 2. Informacje o kolumnach: .info() pokazuje liczbę wierszy, typy danych i liczbę nie-pustych wartości.\n",
        "# Patrząc na 'Non-Null Count', widzimy, że kolumna 'Salary' ma braki danych (tylko 263 nie-pustych wartości z 322).\n",
        "Hitters_small.info()\n",
        "\n",
        "# 3. Podstawowe statystyki opisowe: .describe() dla zmiennych numerycznych\n",
        "# Pokazuje średnią (mean), odchylenie standardowe (std), min, max i kwartyle, co daje wgląd w rozkład zmiennych.\n",
        "Hitters_small.describe()\n",
        "\n",
        "# 4. Wizualizacja rozkładów: histogramy\n",
        "# Używamy .hist() z Pandas, aby zobaczyć rozkład każdej zmiennej.\n",
        "Hitters_small.hist(sharex = False, sharey = False, bins = 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQnOlEK2bTi1"
      },
      "outputs": [],
      "source": [
        "# 5. Model nie może uczyć się na brakujących danych, dlatego musimy je usunąć lub uzupełnić.\n",
        "# Ponieważ braki są tylko w zmiennej 'Salary' (nasza zmienna docelowa 'y'), najlepiej usunąć całe wiersze.\n",
        "Hitters_clean = Hitters_small.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTbHcjLHbTi1"
      },
      "outputs": [],
      "source": [
        "# c) Podział na cechy (X) i zmienną docelową (y)\n",
        "\n",
        "# X - Cechy (zmienne niezależne, 'predyktory'): na podstawie Years i Hits będziemy przewidywać Salary.\n",
        "X = Hitters_clean.drop([\"Salary\"], axis=1)\n",
        "\n",
        "# y - Zmienna docelowa (zmienna zależna, 'target'): to, co chcemy przewidzieć.\n",
        "y = Hitters_clean.Salary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Eksperyment - transformacja log zmiennych skośnych\n",
        "\n",
        "experiment = pd.DataFrame({\"Var1\" : Hitters.Salary,\n",
        "                           \"Var2\": (-Hitters.Salary) + 2000})\n",
        "\n",
        "experiment[\"log(Var1)\"] = np.log(experiment.Var1)\n",
        "experiment[\"log(Var2)\"] = np.log(experiment.Var2)\n",
        "\n",
        "experiment.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qfvj5-ofbTi1"
      },
      "outputs": [],
      "source": [
        "# d) Podział na zbiór treningowy i testowy\n",
        "\n",
        "# Dzielimy dane na dwie części:\n",
        "# 1. Zbiór Treningowy (Training Set): Używany do nauki modelu.\n",
        "# 2. Zbiór Testowy (Test Set): Używany do oceny, jak model radzi sobie z danymi, których 'nie widział'.\n",
        "\n",
        "# 'train_test_split' z biblioteki sklearn automatycznie dokonuje podziału.\n",
        "# 'test_size=0.5' oznacza podział 50% na testowy i 50% na treningowy.\n",
        "# 'random_state=123' to tzw. \"ziarno losowości\" - użycie stałej liczby sprawia, że podział jest zawsze taki sam. Jest to ważne dla powtarzalności wyników.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVyJkFGVbTi2"
      },
      "source": [
        "#### 3.3 Podstawy drzew decyzyjnych \n",
        "\n",
        "#### *Jak się buduje drzewa dla zadania regresji?*\n",
        "1. Dzielimy przestrzeń $X = (X_1, X_2, \\dots, X_p)$ na $J$ regionów $R_1, R_2, \\dots, R_J$.\n",
        "2. Predykcja w $j$-ty regionie jest równa średniej z wartości obserwacji $y$ zbioru treningowego w regione $R_J$. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tworzymy obiekt klasy DecisionTreeRegressor.\n",
        "# Drzewo będzie miało domyślne parametry.\n",
        "Tree = tree.DecisionTreeRegressor()\n",
        "\n",
        "# Trening (uczenie) modelu: Używamy metody .fit(), aby nauczyć model na danych treningowych.\n",
        "Tree.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wizualizacja drzewa decyzyjnego"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV5KgooFbTi2"
      },
      "outputs": [],
      "source": [
        "tree.plot_tree(Tree,\n",
        "               feature_names=X.columns.tolist(), # Nazwy kolumn cech\n",
        "               filled=True # Wypełnienie węzłów kolorem\n",
        "               ) \n",
        "plt.title(\"Drzewo Decyzyjne\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Przejrzysty zapis otrzymanego drzewa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import export_text\n",
        "t = export_text(Tree)\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Drzewo o trzech liściach**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Poprzez wskazywanie hiperparametrów możemy manipulować skompliowaniem i jakością modelu drzewa. Zbudujmy drzewo o hiperparametrze `max_leaf_nodes` = 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDLuG6X8bTi2"
      },
      "outputs": [],
      "source": [
        "Tree3 = tree.DecisionTreeRegressor(max_leaf_nodes=3)\n",
        "Tree3 = Tree3.fit(X_train, y_train)\n",
        "\n",
        "tree.plot_tree(Tree3, \n",
        "               feature_names=Tree3.feature_names_in_.tolist(),\n",
        "               filled=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.4 Jak dobry jest nasz model (zadanie regresji)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Błąd średniokwadratowy:\n",
        "\n",
        "$MSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{f}(x_i))^2$,\n",
        "\n",
        "gdzie:\n",
        "\n",
        "$y_i$ - wartość prawdziwa dla $i$-tej obserwacji,\n",
        "\n",
        "$\\hat{f}(x_i)$ jest predykcją modelu dla $i$-tej obserwacji."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3d0GwKsbTi3"
      },
      "outputs": [],
      "source": [
        "# Generowanie prognoz (Prediction)\n",
        "# Używamy wytrenowanych modeli do przewidywania wartości 'Salary' na nieznanych danych (X_test).\n",
        "y_pred = Tree.predict(X_test)\n",
        "y_pred3 = Tree3.predict(X_test)\n",
        "\n",
        "# Obliczanie Błędu Średniokwadratowego (Mean Squared Error - MSE)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mse3 = mean_squared_error(y_test, y_pred3)\n",
        "\n",
        "print(f\"MSE dla Tree: {mse:.2f}\")\n",
        "print(f\"MSE dla Tree3 (max_depth=3): {mse3:.2f}\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3UzJ6aRbTi3"
      },
      "outputs": [],
      "source": [
        "# Wizualizacja prognoz na tle rzeczywistych wartości\n",
        "df = pd.DataFrame({'y_test':y_test, 'y_pred':Tree3.predict(X_test)})\n",
        "\n",
        "# Tworzymy wykres rozrzutu (scatter plot)\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "\n",
        "# Dane: rzeczywista pensja (y_test) vs. przewidywana pensja (y_pred)\n",
        "df.plot(x='y_test', y='y_pred', kind='scatter', ax=ax, title=\"Prognoza (Y_pred) vs. Rzeczywistość (Y_test) dla Tree3\")\n",
        "\n",
        "\n",
        "# Idealny model miałby wszystkie punkty na linii Y_test = Y_pred\n",
        "df.plot(x='y_test', y='y_pred', kind='scatter', ax=ax)\n",
        "ax.plot(np.array([0, 2000]), np.array([0, 2000]), color='red')\n",
        "\n",
        "# Interpretacja wykresu: Im bliżej czerwonej linii są punkty, tym lepsze są przewidywania modelu."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
