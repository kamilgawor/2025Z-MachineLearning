{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a717775",
   "metadata": {},
   "source": [
    "## Wstęp do Uczenia Maszynowego \n",
    "#### Laboratorium 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32d9a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import potrzebnych pakietów\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932668d0",
   "metadata": {},
   "source": [
    "### 0. Drzewa decyzyjne - regresja\n",
    "\n",
    "Na chwilę wrócimy do zajęć lab 01.\n",
    "\n",
    "Pracowaliśmy ostatnio nad zadaniem regresji i przewidywaniem wynagrodzenia dla zawodników Baseballu.\n",
    "\n",
    "Stworzyliśmy pierwszy model i ocenialiśmy jego jakość mierząc błąd średniokwadratowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Kod pobierający danych\n",
    "Hitters = pd.read_csv(\"https://raw.githubusercontent.com/kozaka93/2025Z-MachineLearning/refs/heads/main/labs/lab01/Hitters.csv\", index_col =[0])\n",
    "## Ograniczamy zbiór do trzech zmiennych \n",
    "Hitters_small = Hitters[[\"Years\", \"Hits\", \"Salary\"]]\n",
    "## Usuwamy braki danych\n",
    "Hitters_small = Hitters_small.dropna()\n",
    "\n",
    "## Dzielimy zbior danych na y (zmienna docelowa) i X (zmienne wejściowe) oraz na train i test.\n",
    "y = Hitters_small.Salary\n",
    "X = Hitters_small.drop([\"Salary\"], axis=1) \n",
    "# Podział na zbiór treningowy (do uczenia) i testowy (do oceny)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=123)\n",
    "\n",
    "## Budujemy drzewo z 3 liśćmi (regresja).\n",
    "Tree3 = DecisionTreeRegressor(max_leaf_nodes=3)\n",
    "Tree3 = Tree3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260fc79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rysunek drzewa\n",
    "plot_tree(Tree3, \n",
    "          feature_names=Tree3.feature_names_in_.tolist(), \n",
    "          filled=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335298cf",
   "metadata": {},
   "source": [
    "### Regiony \n",
    "\n",
    "<img src=\"Five-Region-Examples.png\" width=\"400\"/>\n",
    "\n",
    "###### Źródło:  James, G., Witten, D., Hastie, T., Tibshirani, R., Taylor, J. (2023). An Introduction to Statistical Learning with Applications in Python, Springer Science+Business Media, New York. https://www.statlearning.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fbe8f6",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 1*\n",
    "------\n",
    "Na podstawie informacji o utworzonym drzewie zdefiniuj regiony $R_1$, $R_2$ i $R_3$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d568b7b",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 2*\n",
    "------\n",
    "Na bazie przedstawionych poniżej regionów narysuj odpowiadające im drzewo decyzyjne.\n",
    "\n",
    "<img src=\"Regions_Task.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959912ef",
   "metadata": {},
   "source": [
    "#### Jak konstruować regiony w przypadku drzewa dla zadania regresji?\n",
    "**Cel**: Znaleźć $R_1, R_2, \\dots, R_J$, które minimalizują $RSS$.\n",
    "\n",
    "$$RSS = \\sum_{j = 1}^{J} \\sum_{i \\in R_j}^{}(y_i - \\hat{y}_{R_j})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361da85f",
   "metadata": {},
   "source": [
    "Niestety nie jesteśmy w stanie rozpatrzeć wszystkich możliwości - zbyt złożone obliczeniowo.\n",
    "\n",
    "Używamy podejścia *top-down, greedy*:\n",
    "- *top-down* - zaczynamy od wszystkich obserwacji w jednym regione i następnie w kolejnych krokach rozdzielamy na mniejsze regiony\n",
    "- *greedy* - na każdym etapie procesu budowania drzewa dokonywany jest najlepszy podział, nie patrzymy w przyszłość\n",
    "\n",
    "Proces powatrzamy do momentu spełnienia kryterium stopu, np. w liściu nie może być mniej niż 5 obserwacji.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d08b6a",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 3*\n",
    "------\n",
    "\n",
    "Przeprowadź eksperyment pokazujący wartość miary MSE na zbiorze treningowym i testowym w zależności od wartości parametru `max_leaf_nodes` - zakres 2:30.\n",
    "\n",
    "`max_leaf_nodes` - Grow a tree with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes (default=None).\n",
    "\n",
    "Narysuj wykres przedstawiający wyniki eksperymentu. Jaka jest optymalna wartość parametru `max_leaf_nodes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f0456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error # Funkcja do obliczania Błędu Średniokwadratowego (MSE)\n",
    "mse_train = [] # Lista do przechowywania wartości MSE na zbiorze treningowym\n",
    "mse_test = [] # Lista do przechowywania wartości MSE na zbiorze testowym\n",
    "\n",
    "# Pętla, która będzie iterować przez różne wartości max_leaf_nodes (od 2 do 30)\n",
    "for i in range(2, 31):\n",
    "    # Tworzenie modelu drzewa regresyjnego z aktualną maksymalną liczbą liści (i)\n",
    "    Tree_i = DecisionTreeRegressor(max_leaf_nodes=i)\n",
    "    # Uczenie modelu na danych treningowych\n",
    "    Tree_i.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = Tree_i.predict(X_train) # Predykcje modelu dla danych treningowych.\n",
    "    mse_train.append(mean_squared_error(y_train, y_train_pred)) # Obliczenie i zapisanie MSE_train.\n",
    "    \n",
    "    y_test_pred = Tree_i.predict(X_test) # Predykcje modelu dla danych testowych\n",
    "    mse_test.append(mean_squared_error(y_test, y_test_pred)) # Obliczenie i zapisanie MSE_test.\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tworzenie wykresu\n",
    "plt.figure(figsize=(10, 6)) \n",
    "plt.plot(range(2, 31), mse_train, label='MSE Train', marker='o') \n",
    "plt.plot(range(2, 31), mse_test, label='MSE Test', marker='o') \n",
    "plt.xlabel('Liczba liści (max_leaf_nodes)') \n",
    "plt.ylabel('Błąd średniokwadratowy (MSE)') \n",
    "plt.title('MSE vs. max_leaf_nodes') \n",
    "plt.legend() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c551ebb3",
   "metadata": {},
   "source": [
    "### 1. Drzewa decyzyjne - klasyfikacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35984da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie zbioru danych Pima Indians Diabetes, używanego do klasyfikacji (przewidywania cukrzycy)\n",
    "pima = pd.read_csv(\"pima.csv\")\n",
    "# pima = pd.read_csv(\"link do raw GitHub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fb0527",
   "metadata": {},
   "source": [
    "Więcej o danych: https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e009b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f52f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf19db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.Outcome.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0116945",
   "metadata": {},
   "source": [
    "### Kryterium podziału\n",
    "a) wskaźnik błędu klasyfikacji (*classification error rate*) = udział obserwacji ze zbioru treningowego w danym regionie, które nie należą do przeważającej klasy.\n",
    "    \n",
    "$$E = 1 - max_{k}(\\hat{p}_{mk}) $$\n",
    " \n",
    "$\\hat{p}_{mk}$ - proporcja obserwacji zbioru treningowego w m-tym regionie pochodząca z k-tej klasy\n",
    "   \n",
    "b) indeks Giniego   \n",
    "\n",
    " $$G = \\sum_{k=1}^{K}\\hat{p}_{mk}(1-\\hat{p}_{mk})$$\n",
    "\n",
    "Indeks Giniego przyjmuje małe wartości jeżeli $\\hat{p}_{mk}$ jest bliski 0 lub 1. Z tego powodu indeks Giniego jest określany jako miara czystości węzła (*node purity*) - mała wartość wskazuje, że węzeł zawiera głównie obserwacje z jednej klasy.\n",
    "\n",
    "c) entropia\n",
    " \n",
    " $$D = - \\sum_{k=1}^{K}\\hat{p}_{mk}log\\hat{p}_{mk}$$\n",
    "\n",
    " $0 \\leq \\hat{p}_{mk} \\leq 1 \\ \\rightarrow 0 \\leq -\\hat{p}_{mk}log\\hat{p}_{mk}$\n",
    "\n",
    "Podobnie jak indeks Giniego przyjmuje małe wartości (bliskie zero) gdy $\\hat{p}_{mk}$ jest bliskie 0 lub 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d71c4",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 4*\n",
    "------\n",
    "\n",
    "Przygotuj zbiór danych pima do dalszej pracy. Podziel na `X` i `y`, a następnie na zbiór treningowy i testowy w proporcji 7:3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab926c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dzielimy zbiór danych Pima na zmienne wejściowe (X) i zmienną docelową (y).\n",
    "# Zmienna docelowa 'Outcome' (wynik) to kolumna, którą chcemy przewidzieć (klasa 0 lub 1).\n",
    "y_pima = pima.Outcome \n",
    "X_pima = pima.drop(['Outcome'], axis=1)\n",
    "\n",
    "# Dzielimy dane na zbiór treningowy (70%) i testowy (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pima, y_pima, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2726a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzenie rozmiaru zbiorów po podziale\n",
    "print(f\"Rozmiar zbioru treningowego X: {X_train.shape}\")\n",
    "print(f\"Rozmiar zbioru testowego X: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d261bd8",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 5*\n",
    "------\n",
    "Zbuduj model drzewa dla danych z Zadania 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4635f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "# Tworzenie obiektu Drzewa Decyzyjnego do Klasyfikacji\n",
    "Tree = DecisionTreeClassifier()\n",
    "\n",
    "# Uczenie modelu na danych treningowych\n",
    "Tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012c6684",
   "metadata": {},
   "source": [
    "#### Macierz pomyłek (ang. confusion matrix)\n",
    "\n",
    "#### Jak dobry jest nasz model (zadanie klasyfikacji)?\n",
    "\n",
    "Drzewa Decyzyjne mogą być używane również do klasyfikacji. W przypadku klasyfikacji używamy innych metryk oceny.\n",
    "\n",
    "**Macierz pomyłek (ang. confusion matrix)**\n",
    "\n",
    "Macierz pomyłek jest kluczowym narzędziem do oceny modeli klasyfikacyjnych. \n",
    "\n",
    "\n",
    "  * **True Positive (TP):** Model przewidział \"tak\" i była to prawda (rzeczywiście pozytyw).\n",
    "  * **True Negative (TN):** Model przewidział \"nie\" i była to prawda (rzeczywiście negatyw).\n",
    "  * **False Positive (FP):** Model przewidział \"tak\", ale była to pomyłka (fałszywy alarm).\n",
    "  * **False Negative (FN):** Model przewidział \"nie\", ale była to pomyłka (przeoczenie).\n",
    "  \n",
    "<img src=\"confusion_matrix.png\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6feff",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 6*\n",
    "------\n",
    "Wyznacz macierz pomyłek dla predykcji na danych treningowych i testowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4150a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix # Funkcja do obliczania macierzy pomyłek\n",
    "\n",
    "y_train_pred = Tree.predict(X_train)\n",
    "\n",
    "# Obliczamy macierz pomyłek, porównując prawdziwe etykiety (y_train) z predykcjami (y_train_pred)\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "# Wyświetlenie macierzy pomyłek.\n",
    "print(\"Macierz pomyłek (dane treningowe):\")\n",
    "print(conf_matrix_train)\n",
    "\n",
    "\n",
    "y_test_pred = Tree.predict(X_test)\n",
    "\n",
    "# Obliczamy macierz pomyłek, porównując prawdziwe etykiety (y_test) z predykcjami (y_test_pred)\n",
    "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Wyświetlenie macierzy pomyłek.\n",
    "print(\"Macierz pomyłek (dane testowe):\")\n",
    "print(conf_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ec5c29",
   "metadata": {},
   "source": [
    "\n",
    "Metryki bazujące na macierzy pomyłek:\n",
    "\n",
    "  - **Dokładność (Accuracy):** Jak duży odsetek wszystkich prognoz był poprawny.\n",
    "    $$\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "  - **Czułość (Recall) / Pełność:** Jak duży odsetek wszystkich **rzeczywistych pozytywów** został poprawnie zidentyfikowany.\n",
    "    $$\\text{Recall} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "  - **Precyzja (Precision):** Jak duży odsetek wszystkich **prognoz pozytywnych** był faktycznie poprawny.\n",
    "    $$\\text{Precision} = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "  - **F1-Score:** Średnia harmoniczna Precyzji i Czułości. Jest używany, gdy chcemy równowagi między tymi dwoma metrykami.\n",
    "    $$\\text{F1-Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416c54e1",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 7*\n",
    "------\n",
    "Dla utworzonego modelu wylicz powyższe metryki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d23ba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score # Import funkcji do obliczania metryk\n",
    "\n",
    "# Obliczanie Dokładności (Accuracy):\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Obliczanie Czułości (Recall):\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "\n",
    "# Obliczanie Precyzji (Precision):\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "\n",
    "# Obliczanie F1-Score:\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Dokładność (Accuracy) na zbiorze testowym: {accuracy:.4f}\")\n",
    "print(f\"Czułość (Recall) na zbiorze testowym: {recall:.4f}\")\n",
    "print(f\"Precyzja (Precision) na zbiorze testowym: {precision:.4f}\")\n",
    "print(f\"F1-Score na zbiorze testowym: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cedead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
