{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wstęp do Uczenia Maszynowego \n",
    "##### Laboratorium 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Kroswalidacja (*ang. cross validation*) vs Leave One Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 1*\n",
    "------\n",
    "Wymień zalety i wady kroswalidacji.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zalety:\n",
    "\n",
    "\n",
    "Wady:\n",
    "\n",
    "\n",
    "----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import potrzebnych bibliotek i modułów\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych\n",
    "pima = pd.read_csv(\"../lab02/pima.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicja zbioru X i y\n",
    "y = pima.Outcome\n",
    "X = pima.drop([\"Outcome\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 2*\n",
    "------\n",
    "Używając funkcji `cross_val_score()` oszacuj wartość średnią oraz odchylenie standardowe 10-krotnej kroswalidacji dla modelu drzewa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 3*\n",
    "------\n",
    "Przeprowadź na zbiorze danych `pima.csv` 100 razy 10-krotną kroswalidację i przestaw otrzymane wyniki (miara `roc_auc`) - średnią oraz odchylenie standardowe. Narysuj rozkład otrzymanych wyników.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Krzywa ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak się wylicza krzywą ROC?\n",
    "\n",
    "1. Potrzebujemy wyliczyć FPR (false positive ratio) i TPR (true positive ratio) dla różnych rozważanych progów odcięcia.\n",
    "\n",
    "$FPR = \\frac{FP}{FP + TN}$\n",
    "\n",
    "$TPR = \\frac{TP}{TP + FN}$\n",
    "\n",
    "2. Przykład\n",
    "\n",
    "$y = [0, 0, 1, 1]$\n",
    "\n",
    "$y_{pred} = [0.1, 0.35, 0.4, 0.8]$\n",
    "\n",
    "$treshold = [\\infty, 0.1, 0.35, 0.4, 0.8]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 4*\n",
    "------\n",
    "Przygotuj model do oceny metodą `roc_auc`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Podsumowanie, czyli co warto wiedzieć...\n",
    "\n",
    "1. Jak definiujemy problem klasyfikacji?\n",
    "2. Podział zbioru na treningowy, walidacyjny i testowy.\n",
    "2. Miary dokładności klasyfikatorów:\n",
    "\n",
    "    a) macierz pomyłek (*ang. confusion matrix*),\n",
    "\n",
    "    b) dokładność, czułość, precyzja, (*ang. accuracy, recall, precision*)\n",
    "\n",
    "    c) krzywa ROC,\n",
    "\n",
    "    d) AUC.\n",
    "\n",
    "\n",
    "3. Kroswalidacja (*ang. cross validation*)\n",
    "4. Drzewa decyzyjne:\n",
    "\n",
    "    a) wady i zalety,\n",
    "\n",
    "    b) jak budujemy drzewo,\n",
    "\n",
    "    b) jakie mamy miary podziału,\n",
    "    \n",
    "    d) przycinanie drzew."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
