{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wstęp do Uczenia Maszynowego \n",
    "##### Laboratorium 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Kroswalidacja (*ang. cross validation*) vs Leave One Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 1*\n",
    "------\n",
    "Wymień zalety i wady kroswalidacji.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zalety:\n",
    "- dobrze działa w praktyce\n",
    "- używamy wszystkich danych jako zbiór treningowy i testowy\n",
    "\n",
    "Wady:\n",
    "- zbiór treningowy i testowy nie są niezależne \n",
    "- możemy policzyć odchylenie standardowe, ale nie ma gwarancji na nie\n",
    "- błąd jest obarczony błędem (bias) - próbki treningowe są mniejsze niż pełny zbiór\n",
    "- wydłużenie czasu budowy, $k$ razy trzeba trenowac modele\n",
    "\n",
    "----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import potrzebnych bibliotek i modułów\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych\n",
    "pima = pd.read_csv(\"../lab02/pima.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicja zbioru X i y\n",
    "y = pima.Outcome\n",
    "X = pima.drop([\"Outcome\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 1.5*\n",
    "------\n",
    "\n",
    "Dla danych `pima` zbadaj zachowanie hiperparametru modelu drzewa klasyfikacyjnego `max_leaf_nodes` w zakresie od 2 do 30 na zbiorze treningowym i testowym. Oblicz miarę dokładości, precyzji i AUC. Przygotuj wizualizacje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score\n",
    "acc_train = [] \n",
    "acc_test = [] \n",
    "auc_train = [] \n",
    "auc_test = [] \n",
    "prec_train = [] \n",
    "prec_test = [] \n",
    "\n",
    "for i in range(2, 31):\n",
    "    Tree_i = tree.DecisionTreeClassifier(max_leaf_nodes=i)\n",
    "    # Uczenie modelu na danych treningowych\n",
    "    Tree_i.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = Tree_i.predict(X_train) # Predykcje modelu dla danych treningowych (klasy)\n",
    "    y_train_pred_proba = Tree_i.predict_proba(X_train)[:,1] # Predykcje modelu dla danych treningowych (prawdopodobieństwa)\n",
    "    acc_train.append(accuracy_score(y_train, y_train_pred)) # Wyliczenie dokładności dla zbioru treningowego\n",
    "    auc_train.append(roc_auc_score(y_train, y_train_pred_proba)) # Wyliczenie AUC dla zbioru treningowego\n",
    "    prec_train.append(precision_score(y_train, y_train_pred)) # Wyliczenie precyzji dla zbioru treningowego\n",
    "    \n",
    "    y_test_pred = Tree_i.predict(X_test) # Predykcje modelu dla danych testowych (klasy)\n",
    "    y_test_pred_proba = Tree_i.predict_proba(X_test)[:,1] # Predykcje modelu dla danych testowych (prawdopodobieństwa)\n",
    "    acc_test.append(accuracy_score(y_test, y_test_pred)) # Wyliczenie dokładności dla zbioru testowego\n",
    "    auc_test.append(roc_auc_score(y_test, y_test_pred_proba)) # Wyliczenie AUC dla zbioru testowego\n",
    "    prec_test.append(precision_score(y_test, y_test_pred)) # Wyliczenie precyzji dla zbioru testowego\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "max_leaf_nodes_range = np.arange(2, 31)\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Dokładność\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(max_leaf_nodes_range, acc_train, label='Trening')\n",
    "plt.plot(max_leaf_nodes_range, acc_test, label='Test')\n",
    "plt.title('Accuracy (Dokładność)')\n",
    "plt.xlabel('max_leaf_nodes')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.legend()\n",
    "\n",
    "# AUC\n",
    "plt.subplot(1, 3, 2) \n",
    "plt.plot(max_leaf_nodes_range, auc_train, label='Trening')\n",
    "plt.plot(max_leaf_nodes_range, auc_test, label='Test')\n",
    "plt.title('ROC AUC Score')\n",
    "plt.xlabel('max_leaf_nodes')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.legend()\n",
    "\n",
    "# Precyzja\n",
    "plt.subplot(1, 3, 3) \n",
    "plt.plot(max_leaf_nodes_range, prec_train, label='Trening')\n",
    "plt.plot(max_leaf_nodes_range, prec_test, label='Test')\n",
    "plt.title('Precision (Precyzja)')\n",
    "plt.xlabel('max_leaf_nodes')\n",
    "plt.ylabel('Precision Score')\n",
    "plt.legend()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 2*\n",
    "------\n",
    "Używając funkcji `cross_val_score()` oszacuj wartość średnią oraz odchylenie standardowe 10-krotnej kroswalidacji dla modelu drzewa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podział zbioru na próbkę treningową i testową\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Budowa modelu drzewa używając kroswalidacji na zbiorze treningowym\n",
    "Tree = tree.DecisionTreeClassifier()\n",
    "scores = cross_val_score(Tree, X_train, y_train, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 3*\n",
    "------\n",
    "Przeprowadź na zbiorze danych `pima.csv` 100 razy 10-krotną kroswalidację i przestaw otrzymane wyniki (miara `roc_auc`) - średnią oraz odchylenie standardowe. Narysuj rozkład otrzymanych wyników.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Budowa drzewa\n",
    "Tree = tree.DecisionTreeClassifier()\n",
    "scores_all = []\n",
    "for i in range(0, 100):\n",
    "    # Kroswalidacja 10-krotna (parametr \"cv\") z miarą roc_auc (parametr \"scoring\")\n",
    "    scores = cross_val_score(Tree, X_train, y_train, cv = 10, scoring = 'roc_auc')\n",
    "    scores_all.append(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ramka danych tworzona z listy list\n",
    "df = pd.DataFrame(scores_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyliczenie średniej i narysowanie histogramu\n",
    "df.aggregate([\"mean\", \"std\"], axis=1)[\"mean\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyliczenie odchylenia standardowego i narysowanie histogramu\n",
    "df.aggregate([\"mean\", \"std\"], axis=1)[\"std\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Krzywa ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak się wylicza krzywą ROC?\n",
    "\n",
    "1. Potrzebujemy wyliczyć FPR (false positive ratio) i TPR (true positive ratio) dla różnych rozważanych progów odcięcia.\n",
    "\n",
    "$FPR = \\frac{FP}{FP + TN}$\n",
    "\n",
    "$TPR = \\frac{TP}{TP + FN}$\n",
    "\n",
    "2. Przykład\n",
    "\n",
    "$y = [0, 0, 1, 1]$\n",
    "\n",
    "$y_{pred} = [0.1, 0.4, 0.35, 0.8]$\n",
    "\n",
    "$treshold = [0.1, 0.35, 0.4, 0.8]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 5*\n",
    "------\n",
    "Przygotuj model do oceny metodą `roc_auc`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trzy różne modele drzewa.\n",
    "Tree1 = tree.DecisionTreeClassifier()\n",
    "Tree2 = tree.DecisionTreeClassifier(max_depth=3)\n",
    "Tree3 = tree.DecisionTreeClassifier(max_leaf_nodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trening modeli\n",
    "Tree1 = Tree1.fit(X_train, y_train)\n",
    "Tree2 = Tree2.fit(X_train, y_train)\n",
    "Tree3 = Tree3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predykcja modeli - prawdopodobieństwa\n",
    "pred1 = Tree1.predict_proba(X_test)\n",
    "pred2 = Tree2.predict_proba(X_test)\n",
    "pred3 = Tree3.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyliczanie krzywej ROC dla 3 modeli\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred1[:,1])\n",
    "plt.plot(fpr,tpr,label=\"Tree, AUC=\"+str(round(roc_auc_score(y_test, pred1[:,1]), 4)))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred2[:,1])\n",
    "plt.plot(fpr,tpr,label=\"Tree, max_depth=3, AUC=\"+str(round(roc_auc_score(y_test, pred2[:,1]), 4)))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred3[:,1])\n",
    "plt.plot(fpr,tpr,label=\"Tree, max_leaf_nodes=5, AUC=\"+str(round(roc_auc_score(y_test, pred3[:,1]), 4)))\n",
    "plt.title('ROC AUC')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drugi sposób rysowanie krzywej ROC\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "RocCurveDisplay.from_estimator(Tree1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyliczenia miary AUC.\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, Tree1.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Podsumowanie, czyli co warto wiedzieć...\n",
    "\n",
    "1. Jak definiujemy problem klasyfikacji?\n",
    "2. Podział zbioru na treningowy, walidacyjny i testowy.\n",
    "2. Miary dokładności klasyfikatorów:\n",
    "\n",
    "    a) macierz pomyłek (*ang. confusion matrix*),\n",
    "\n",
    "    b) dokładność, czułość, precyzja, (*ang. accuracy, recall, precision*)\n",
    "\n",
    "    c) krzywa ROC,\n",
    "\n",
    "    d) AUC.\n",
    "\n",
    "\n",
    "3. Kroswalidacja (*ang. cross validation*)\n",
    "4. Drzewa decyzyjne:\n",
    "\n",
    "    a) wady i zalety,\n",
    "\n",
    "    b) jak budujemy drzewo,\n",
    "\n",
    "    b) jakie mamy miary podziału,\n",
    "    \n",
    "    d) przycinanie drzew."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
